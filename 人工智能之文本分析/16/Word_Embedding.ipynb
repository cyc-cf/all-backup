{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeys\\Desktop\\workspace\\文本分析\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim\n",
    "from gensim.models import word2vec #詞轉向量\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "##讀model出來\n",
    "# model = KeyedVectors.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin', binary=True) #google english model\n",
    "model = KeyedVectors.load_word2vec_format(cwd+'/Word2Vec/data/W2V_ZH/zhwiki_2017_03.sg_50d.word2vec', binary=False) #zh model\n",
    "# model = word2vec.Word2Vec.load(cwd+'/models/wiki_model.bin') #繁體 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Length: 50\n",
      "[-0.3466399908065796, -0.43724098801612854, 0.1707880049943924, 0.022954000160098076, 0.4161989986896515, -0.0840189978480339, -0.25948500633239746, -0.806056022644043, 0.805305004119873, 0.5656319856643677, 0.5925989747047424, -0.7587100267410278, 0.9751279950141907, 0.29714998602867126, -0.008059999905526638, -0.47452598810195923, -0.06402499973773956, -0.046073999255895615, -0.46143200993537903, 0.05852599814534187, -0.12438099831342697, 0.06608500331640244, -0.3177359998226166, 0.11189699918031693, 0.61455899477005, -0.04680600017309189, -0.3722279965877533, 0.04780000075697899, 0.5564839839935303, -0.4300920069217682, -0.3466010093688965, 0.29884400963783264, -0.5356000065803528, 0.23637600243091583, 0.08271799981594086, 0.33768099546432495, -0.3944390118122101, -0.22378599643707275, -0.2952539920806885, -0.0026140001136809587, 0.13818800449371338, 0.09636600315570831, 0.5633080005645752, -0.12280499935150146, -0.2777920067310333, -0.0529169999063015, -0.6962310075759888, 0.32405200600624084, 0.19305700063705444, 0.10947500169277191]\n",
      "人工智慧    \t 0.912\n",
      "机器人学    \t 0.861\n",
      "软件工程    \t 0.861\n",
      "软件设计    \t 0.852\n",
      "AI      \t 0.848\n",
      "可视化     \t 0.846\n",
      "专家系统    \t 0.842\n",
      "虚拟现实    \t 0.842\n",
      "计算机     \t 0.835\n",
      "数据挖掘    \t 0.826\n",
      "\n",
      "[('上海', 0.85248863697052), ('广州', 0.8133988380432129), ('南京', 0.8087798953056335), ('沈阳', 0.8043987154960632), ('长春', 0.7917946577072144), ('哈尔滨', 0.7850497364997864), ('杭州', 0.7794261574745178), ('济南', 0.7794216871261597), ('福寿园', 0.7779054045677185), ('潞河', 0.7772673964500427)]\n",
      "\n",
      "[('高雄', 0.9592850208282471), ('台中', 0.9110101461410522), ('台北市', 0.9060338735580444), ('台南', 0.8943192362785339), ('高雄市', 0.8909018039703369), ('于台', 0.8856596946716309), ('嘉义', 0.8800873160362244), ('花莲', 0.8800070285797119), ('屏东', 0.8773597478866577), ('桃园', 0.8749310374259949)]\n"
     ]
    }
   ],
   "source": [
    "print('Vector Length: ' + str(len(model['人工智能'].tolist())))\n",
    "print(model['人工智能'].tolist()) #取vector\n",
    "#print(model.wv.vocab.keys()) #所有的詞\n",
    "\n",
    "semi = ''\n",
    "\n",
    "try:\n",
    "    semi = model.most_similar('人工智能',topn=10) #與keyword最相似的k個詞\n",
    "except KeyError:\n",
    "    print('The word is not in vocalbulary')\n",
    "\n",
    "for term in semi:\n",
    "    print('%-7s \\t %.3f'%(term[0],term[1]))\n",
    "\n",
    "print()\n",
    "print(model.most_similar('北京',topn=10))\n",
    "print()\n",
    "print(model.most_similar('台北',topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim\n",
    "from gensim.models import word2vec #詞轉向量\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "##讀model出來\n",
    "model = KeyedVectors.load_word2vec_format(cwd+'/Word2Vec/data/W2V_EN/GoogleNews-vectors-negative300.bin', binary=True) #google english model\n",
    "# model = KeyedVectors.load_word2vec_format(cwd+'/Word2Vec/data/W2V_ZH/zhwiki_2017_03.sg_50d.word2vec', binary=False) #zh model\n",
    "# model = word2vec.Word2Vec.load(cwd+'/models/wiki_model.bin') #繁體 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Length: 300\n",
      "artificial_intelligence        \t 0.700\n",
      "USA_Subjex_Corporation         \t 0.536\n",
      "Artificial_Intelligence_AI     \t 0.528\n",
      "Novamente                      \t 0.525\n",
      "Computational_Intelligence     \t 0.514\n",
      "Ben_Goertzel                   \t 0.514\n",
      "Bot_Colony                     \t 0.505\n",
      "Artificial_Intelligence_AAAI   \t 0.504\n",
      "Information_Retrieval          \t 0.503\n",
      "Neuroeconomics                 \t 0.497\n",
      "\n",
      "[('China', 0.7648462057113647), ('Bejing', 0.761667013168335), ('Shanghai', 0.7191922068595886), ('Beijng', 0.6974372863769531), ('Guangzhou', 0.6878911256790161), ('Chinese', 0.6758180856704712), ('Taipei', 0.6497264504432678), ('inBeijing', 0.6339085102081299), ('Hu', 0.6303641200065613), ('Beijing_Olympics', 0.6279826164245605)]\n",
      "\n",
      "[('Kaohsiung', 0.7428416013717651), ('Taiwan', 0.7370157241821289), ('Taichung', 0.7351551055908203), ('Taoyuan', 0.705295205116272), ('Tainan', 0.685553789138794), ('Taiwanese', 0.6792128086090088), ('Shanghai', 0.6670801639556885), ('Banciao', 0.6663723587989807), ('Taipei_Taiwan', 0.662420392036438), ('Keelung', 0.6606231927871704)]\n"
     ]
    }
   ],
   "source": [
    "print('Vector Length: ' + str(len(model['AI'].tolist())))\n",
    "\n",
    "semi = ''\n",
    "\n",
    "try:\n",
    "    semi = model.most_similar('Artificial_Intelligence',topn=10) #與keyword最相似的k個詞\n",
    "except KeyError:\n",
    "    print('The word is not in vocalbulary')\n",
    "\n",
    "for term in semi:\n",
    "    print('%-30s \\t %.3f'%(term[0],term[1]))\n",
    "\n",
    "print()\n",
    "print(model.most_similar('Beijing',topn=10))\n",
    "print()\n",
    "print(model.most_similar('Taipei',topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim\n",
    "from gensim.models import word2vec #詞轉向量\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "##讀model出來\n",
    "# model = KeyedVectors.load_word2vec_format(cwd+'/Word2Vec/data/W2V_EN/GoogleNews-vectors-negative300.bin', binary=True) #google english model\n",
    "# model = KeyedVectors.load_word2vec_format(cwd+'/Word2Vec/data/W2V_ZH/zhwiki_2017_03.sg_50d.word2vec', binary=False) #zh model\n",
    "model = word2vec.Word2Vec.load(cwd+'/Word2Vec/data/W2V_TW/wiki_model.bin') #繁體 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Length: 250\n",
      "人工智能    \t 0.808\n",
      "機器人學    \t 0.621\n",
      "虛擬世界    \t 0.613\n",
      "電腦病毒    \t 0.612\n",
      "虛擬實境    \t 0.611\n",
      "電腦程式    \t 0.602\n",
      "程式設計    \t 0.596\n",
      "專家系統    \t 0.581\n",
      "電腦系統    \t 0.579\n",
      "人機交互    \t 0.578\n",
      "\n",
      "[('北京市', 0.6514079570770264), ('上海', 0.6486930251121521), ('天津', 0.6235756874084473), ('南京', 0.5676389932632446), ('瀋陽', 0.5674712657928467), ('哈爾濱', 0.5630755424499512), ('北平', 0.5553203821182251), ('中國', 0.5304044485092163), ('廣州', 0.5279752016067505), ('杭州', 0.5276033282279968)]\n",
      "\n",
      "[('台北市', 0.8547413349151611), ('台中市', 0.8135718703269958), ('台南', 0.813475489616394), ('黃聰典', 0.8025586009025574), ('萍蓬草', 0.784456729888916), ('新竹人', 0.7783325910568237), ('阿典', 0.7564539909362793), ('通嫌', 0.7556571960449219), ('企銀', 0.7462084293365479), ('高雄人', 0.7449833750724792)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeys\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\leeys\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "C:\\Users\\leeys\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "C:\\Users\\leeys\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "print('Vector Length: ' + str(len(model['人工智慧'].tolist())))\n",
    "\n",
    "semi = ''\n",
    "\n",
    "try:\n",
    "    semi = model.most_similar('人工智慧',topn=10) #與keyword最相似的k個詞\n",
    "except KeyError:\n",
    "    print('The word is not in vocalbulary')\n",
    "\n",
    "for term in semi:\n",
    "    print('%-7s \\t %.3f'%(term[0],term[1]))\n",
    "\n",
    "print()\n",
    "print(model.most_similar('北京',topn=10))\n",
    "print()\n",
    "print(model.most_similar('台北',topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5439878106117249, 0.5675179362297058, 0.3526456952095032, -0.9448675513267517, -2.0930328369140625]\n",
      "dict_keys(['北京', '吃', '烤鸭', '上海', '饭', '帝都', '玩', '台北', '下午茶'])\n",
      "上海    \t 0.936\n",
      "台北    \t 0.872\n",
      "北京    \t 0.550\n",
      "北京    \t [('台北', 0.8041357398033142), ('帝都', 0.5498136281967163), ('下午茶', 0.4615095555782318)]\n",
      "吃     \t [('玩', 0.5938371419906616), ('北京', 0.26427650451660156), ('台北', 0.22320425510406494)]\n",
      "烤鸭    \t [('下午茶', 0.8976269960403442), ('饭', 0.8137402534484863), ('玩', 0.5967269539833069)]\n",
      "上海    \t [('帝都', 0.9355762004852295), ('台北', 0.6725261807441711), ('烤鸭', 0.39267346262931824)]\n",
      "饭     \t [('下午茶', 0.8853400349617004), ('烤鸭', 0.8137402534484863), ('玩', 0.7984597682952881)]\n",
      "帝都    \t [('上海', 0.9355762004852295), ('台北', 0.8716286420822144), ('北京', 0.5498136281967163)]\n",
      "玩     \t [('饭', 0.7984597682952881), ('下午茶', 0.6208075284957886), ('烤鸭', 0.5967269539833069)]\n",
      "台北    \t [('帝都', 0.8716286420822144), ('北京', 0.8041357398033142), ('上海', 0.6725261807441711)]\n",
      "下午茶   \t [('烤鸭', 0.897627055644989), ('饭', 0.8853400945663452), ('玩', 0.6208075284957886)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeys\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# pip install gensim\n",
    "from gensim.models import word2vec #詞轉向量\n",
    "\n",
    "sentences = word2vec.LineSentence(cwd+'/data/segms.txt') #input 已斷好的詞\n",
    "\n",
    "#sg : 0->CBOW ,1->skip-gram \n",
    "#size : vector size\n",
    "#window : window size\n",
    "#min_count : min_TF\n",
    "model = word2vec.Word2Vec(sentences, sg=1, size=5, window=5, iter=10000, min_count=1)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "print(model['帝都'].tolist()) #取vector\n",
    "print(model.wv.vocab.keys()) #所有的詞\n",
    "\n",
    "try:\n",
    "    semi = model.wv.most_similar('帝都', topn=3) #與keyword最相似的k個詞\n",
    "except KeyError:\n",
    "    print('The word is not in vocalbulary')\n",
    "    \n",
    "for term in semi:\n",
    "    print('%-5s \\t %.3f'%(term[0],term[1]))\n",
    "\n",
    "for w in model.wv.vocab.keys():\n",
    "    print('%-5s \\t %s' % (w, model.wv.most_similar(w, topn=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write s100w5_skipgram ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeys\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# pip install gensim\n",
    "from gensim.models import word2vec #詞轉向量\n",
    "\n",
    "sentences = word2vec.LineSentence(cwd+'/data/segms.txt') #input 已斷好的詞\n",
    "\n",
    "#sg : 0->CBOW ,1->skip-gram \n",
    "#size : vector size\n",
    "#window : window size\n",
    "#min_count : min_TF\n",
    "model = word2vec.Word2Vec(sentences, sg=1, size=5, window=5, iter=10000, min_count=1)\n",
    "\n",
    "model.save(cwd+'/data/skipgram.model')#save model\n",
    "\n",
    "#write vector\n",
    "with open(cwd+'/data/skipgram.csv','w',encoding='utf-8') as f:\n",
    "    f.write('\\ufeff')\n",
    "    for k in model.wv.vocab.keys():\n",
    "        f.write(k+','+','.join(str(e) for e in model[k].tolist()))\n",
    "        f.write('\\n')\n",
    "\n",
    "print('write s100w5_skipgram ok!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Length: 5\n",
      "上海      \t 0.936\n",
      "台北      \t 0.872\n",
      "北京      \t 0.550\n",
      "\n",
      "[('台北', 0.8041357398033142), ('帝都', 0.5498136281967163), ('下午茶', 0.4615095555782318)]\n",
      "\n",
      "[('帝都', 0.8716286420822144), ('北京', 0.8041357398033142), ('上海', 0.6725261807441711)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeys\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\leeys\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\leeys\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "C:\\Users\\leeys\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n"
     ]
    }
   ],
   "source": [
    "##讀model出來\n",
    "model = word2vec.Word2Vec.load(cwd+'/data/skipgram.model') #skipgram model\n",
    "\n",
    "print('Vector Length: ' + str(len(model['帝都'].tolist())))\n",
    "\n",
    "semi = ''\n",
    "\n",
    "try:\n",
    "    semi = model.most_similar('帝都',topn=3) #與keyword最相似的k個詞\n",
    "except KeyError:\n",
    "    print('The word is not in vocalbulary')\n",
    "\n",
    "for term in semi:\n",
    "    print('%-7s \\t %.3f'%(term[0],term[1]))\n",
    "\n",
    "print()\n",
    "print(model.most_similar('北京',topn=3))\n",
    "print()\n",
    "print(model.most_similar('台北',topn=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
