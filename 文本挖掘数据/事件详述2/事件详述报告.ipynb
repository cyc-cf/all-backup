{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import collections\n",
    "from pandas.core.frame import DataFrame\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "import re\n",
    "import wordcloud\n",
    "import jieba\n",
    "import jieba.analyse# TF-IDF的关键词的抽取\n",
    "import jieba.posseg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = ['sans-serif'] \n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c2ccc5060e66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrequent_patterns\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapriori\u001b[0m  \u001b[1;31m#挖掘频繁项集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrequent_patterns\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0massociation_rules\u001b[0m \u001b[1;31m#挖掘关联规则\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mlxtend\\frequent_patterns\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# License: BSD 3 clause\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mapriori\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapriori\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfpgrowth\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfpgrowth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfpmax\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfpmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mlxtend\\frequent_patterns\\apriori.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrequent_patterns\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfpcommon\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfpc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\testing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m from pandas._testing import (\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_testing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m \u001b[0mcython_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import mlxtend\n",
    "from mlxtend.frequent_patterns import apriori  #挖掘频繁项集\n",
    "from mlxtend.frequent_patterns import association_rules #挖掘关联规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud,ImageColorGenerator\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引用中文字体\n",
    "WordCloud(font_path='C:\\Windows\\Fonts\\HGDBS_CNKI.TTF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· 读取数据转文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r'E:\\Ajiao\\LiXian\\notebook\\notebook\\事故调查报告列表-中远海重.xls',usecols=[49])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.去除虚词和停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordslist():\n",
    "    stopwordslist =[line.strip() for line in open('D:\\AAA安装\\jieba-0.42.1\\jieba\\dict\\虚词和停用词.txt',encoding='UTF-8').readlines()]\n",
    "    return stopwordslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seg_depart：源列表\n",
    "#stopwordslist:停用词列表\n",
    "def seg_depart(sen):\n",
    "    sen_depart=jieba.cut(sen.strip())\n",
    "    stopwords = stopwordslist()\n",
    "    outstr = ''\n",
    "    for word in sen_depart:\n",
    "        if word not in stopwords:\n",
    "            if word !='\\t':\n",
    "                outstr += word\n",
    "                outstr += ''\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilename = 'D:\\AAA安装\\jieba-0.42.1\\jieba\\dict\\out.txt'\n",
    "outputs = open(outfilename,'w',encoding='UTF-8')\n",
    "# 转文本[data['详细描述'].iloc[i] for i in range(len(data)) if i<=len(data)]\n",
    "\n",
    "for i in [data['详细描述'].iloc[i] for i in range(len(data)) if i<=len(data)]:\n",
    "    empty_word=seg_depart(i)\n",
    "    outputs.write(empty_word+'\\n')\n",
    "outputs.close()\n",
    "print('删除虚词和停用词成功！！！')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('D:\\AAA安装\\jieba-0.42.1\\jieba\\dict\\out.txt','r',encoding='UTF-8')\n",
    "data_mix = f.read()\n",
    "print(data_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.归并词群表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mix_1=re.sub(r'(\\u8131\\u79bb)|(\\u6ed1\\u8131)|(\\u8131\\u5f00)','脱落',data_mix)\n",
    "result_mix_2=re.sub(r'(\\u5207\\u5272)|(\\u4fee\\u5272)|(\\u5272\\u65ad)|(\\u5272\\u5f00)|(\\u5272\\u9664)|(\\u5207\\u9664)|(\\u5272\\u7834)','割伤',result_mix_1)\n",
    "result_mix_3=re.sub(r'(\\u4e0b\\u5760)|(\\u6eda\\u843d)','坠落',result_mix_2)\n",
    "result_mix_4=re.sub(r'(\\u7838\\u4e0b)|(\\u7838\\u5230)','砸伤',result_mix_3)\n",
    "result_mix_5=re.sub(r'\\u7ef7\\u65ad','崩脱',result_mix_4)\n",
    "result_mix_6=re.sub(r'(\\u71c3\\u7206)|(\\u7206\\u70b8)|(\\u7206\\u71c3)|(\\u5f15\\u71c3)|(\\u95ea\\u7206)|(\\u95ea\\u71c3)','爆裂',result_mix_5)\n",
    "result_mix_7=re.sub(r'(\\u4e0b\\u6ed1)|(\\u6ed1\\u5165)|(\\u6ed1\\u52a8)','滑落',result_mix_6)\n",
    "result_mix_8=re.sub(r'(\\u6324\\u538b)','挤伤',result_mix_7)\n",
    "result_mix_9=re.sub(r'(\\u7ede\\u5165)','绞伤',result_mix_8)\n",
    "result_mix_10=re.sub(r'(\\u649e\\u5230)|(\\u649e\\u51fb)|(\\u78b0\\u649e)|(\\u78b0\\u843d)','撞倒',result_mix_9)\n",
    "result_mix_11=re.sub(r'(\\u8e29\\u5230)|(\\u8e29\\u7a7a)|(\\u8e29\\u788e)','踩踏',result_mix_10)\n",
    "result_mix_12=re.sub(r'(\\u503e\\u659c)','倾倒',result_mix_11)\n",
    "result_mix_13=re.sub(r'(\\u6d82\\u88c5)','涂装车间',result_mix_12)#涂装转为涂装车间，以免提取成特征项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.去除时间和英文字母和换行符和年月日"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.sub(r'(\\d+|[a-zA-Z]+|\\n+|[\\u5e74-\\u6708-\\u65e5])','',result_mix_13)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lcut=jieba.lcut(result,cut_all=False)\n",
    "data_lcut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.专业术语词库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_1= 'D:\\AAA安装\\jieba-0.42.1\\jieba\\dict\\专业术语词汇.txt'\n",
    "jieba.load_userdict(dict_1)\n",
    "f = open(dict_1,'r',encoding='UTF-8')\n",
    "for i in f.readlines():\n",
    "    jieba.suggest_freq(i,tune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j =jieba.lcut(result)\n",
    "j\n",
    "#result 因为运行过上个词典了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.去无关词   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1=open('D:\\AAA安装\\jieba-0.42.1\\jieba\\dict\\去无关词.txt',encoding='UTF-8').read()\n",
    "file = jieba.lcut(file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in file:\n",
    "    if i in jieba.lcut(result):\n",
    "        result = result.replace(i,'')  \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.提取特征项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = jieba.analyse.extract_tags(result,topK=30,allowPOS=('v','x','p','r','u','c','e','a','d','f','g'))\n",
    "trait='/'.join(r)\n",
    "trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.帕累托图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cou = []\n",
    "word_list=jieba.lcut(result)\n",
    "for i in range(len(r)):\n",
    "    if r[i] in word_list:\n",
    "        cou.append(word_list.count(r[i]))\n",
    "        i=i+1\n",
    "cou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_trai=DataFrame({'频数':cou},index=r)\n",
    "da_trait=data_trai.sort_values(by=['频数'],ascending=False)\n",
    "da_trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_trait['Characteristic factors']=['Ac1','Ac2','Ac3','Ac4','Ac5','Ac6','Ac7','Ac8','Ac9','Ac10','Ac11','Ac12','Ac13','Ac14','Ac15','Ac16','Ac17','Ac18','Ac19','Ac20','Ac21','Ac22','Ac23','Ac24','Ac25','Ac26','Ac27','Ac28','Ac29','Ac30']\n",
    "da_trait.index = da_trait['Characteristic factors']\n",
    "da_trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = da_trait['频数'].cumsum()/da_trait['频数'].sum()  #计算累计营收比\n",
    "key = p[p>0.8].index[0]  #标记80%，节点索引\n",
    "key_num = da_trait.index.tolist().index(key)#索引位置\n",
    "\n",
    "da_trait['频数'].plot(kind = 'bar', color = '#48D1CC', edgecolor = 'black',alpha = 0.6, width = 0.6,rot=0)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Characteristic factors')\n",
    "\n",
    "plt.xticks(fontsize=8)\n",
    "\n",
    "p.plot(style = '--k.',secondary_y = True)\n",
    "plt.axvline(key_num,color='r',linestyle=\"--\",alpha=0.8)  \n",
    "plt.text(key_num+0.2,p[key],'The cumulative proportion is：%.3f%%' % (p[key]*100), color = 'r')  # 累计占比超过80%的节点\n",
    "plt.ylabel('Frequency cumulative percentage')\n",
    "#这里根据特征因素的数量进行边距的设置\n",
    "plt.xlim(-0.5,len(da_trait['频数'])-0.5)\n",
    "plt.grid(alpha=0.5,linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 绘制词云图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import WordCloud\n",
    "from pyecharts.globals import SymbolType\n",
    "words = [\n",
    "    (\"cut\", 558),\n",
    "    (\"come down\", 500),\n",
    "    (\"dump\", 283),\n",
    "    (\"slide\", 278),\n",
    "    (\"fall off\", 257),\n",
    "    (\"bruise\", 128),\n",
    "    (\"instability\", 112),\n",
    "    (\"ballast\", 103),\n",
    "    (\"clear\", 100),\n",
    "    (\"burst\", 99),\n",
    "    (\"trample\", 83),\n",
    "    (\"bump\", 64),\n",
    "    (\"hoist\", 56),\n",
    "    (\"repair\", 51),\n",
    "    (\"fasten\", 51),\n",
    "    (\"burn\", 50),\n",
    "    (\"avoid\", 47),\n",
    "    (\"smash\", 46),\n",
    "    (\"slip\", 44),\n",
    "    (\"wound\", 40),\n",
    "    (\"fall\", 40),\n",
    "    (\"lighter\", 40),\n",
    "    (\"scald\", 39),\n",
    "    (\"lifting\", 39),\n",
    "    (\"pump pressure\", 36),\n",
    "    (\"sucker\", 36),\n",
    "    (\"transport\", 35),\n",
    "    (\"scratch\", 35),\n",
    "    (\"laceration\", 31),\n",
    "    (\"hook\", 11),\n",
    "]\n",
    "c = (\n",
    "    WordCloud()\n",
    "    .add(\"\", words, word_size_range=[20, 100], shape=SymbolType.DIAMOND)\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"WordCloud-shape-diamond\"))\n",
    "    .render(r\"E:\\基于文本挖掘的船舶建造事故致因分析\\文本挖掘论文\\英文附件\\词云图英文\\wordcloud_diamond.html\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.提取部门    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apart=jieba.analyse.extract_tags(result,topK=13,withWeight=False,allowPOS=('nn',))#从文本中提取部门\n",
    "#提取的是出现的频率最高的前几个\n",
    "apart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 归并词群表 提取部门与特征项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    #将涂装xx转为涂装车间，方便提取部门，而涂装在事故报告中不一定是事故发生在涂装车间，还有可能是在其他车间涂装队的某某参与了工作\n",
    "    if ('涂装科' in data['详细描述'].iloc[i])|('涂装1科' in data['详细描述'].iloc[i])|('涂装2科' in data['详细描述'].iloc[i])|( '舾装工区' in data['详细描述'].iloc[i])|( '舾装部' in data['详细描述'].iloc[i])|('服务工区' in data['详细描述'].iloc[i])|('机电工区' in data['详细描述'].iloc[i]):\n",
    "        data['详细描述'].iloc[i]=re.sub(r'(\\u6d82\\u88c5\\u79d1)','涂装车间',data['详细描述'].iloc[i])\n",
    "        data['详细描述'].iloc[i]=re.sub(r'(\\u6d82\\u88c5\\d\\u79d1)','涂装车间',data['详细描述'].iloc[i])  \n",
    "        data['详细描述'].iloc[i]=re.sub(r'(\\u6d82\\u88c5\\d\\u79d1)','涂装车间',data['详细描述'].iloc[i])        \n",
    "        data['详细描述'].iloc[i]=re.sub(r'(\\u823e\\u88c5\\u5de5\\u533a)','舾装车间',data['详细描述'].iloc[i])\n",
    "        data['详细描述'].iloc[i]=re.sub(r'(\\u823e\\u88c5\\u90e8)','舾装车间',data['详细描述'].iloc[i])\n",
    "        data['详细描述'].iloc[i]=re.sub(r'(\\u670d\\u52a1\\u5de5\\u533a)','服务车间',data['详细描述'].iloc[i])\n",
    "        data['详细描述'].iloc[i]=re.sub(r'(\\u673a\\u7535\\u5de5\\u533a)','机电车间',data['详细描述'].iloc[i])\n",
    "data\n",
    "#没有将 舾装部机装科或舾装部船装科或舾装一体 合并维舾装车间；只是对详细描述进行分析\n",
    "#将舾装部、舾装工区合并为舾装车间\n",
    "#服务工区转为服务车间\n",
    "#机电工区  机电车间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apart_update=['船体车间', '涂装车间', '机电车间', '服务车间', '起运车间', '船台工区', '舾装车间']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u4e0b\\u5760)|(\\u6eda\\u843d)','坠落',data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u8131\\u79bb)|(\\u6ed1\\u8131)|(\\u8131\\u5f00)','脱落',data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u7838\\u4e0b)|(\\u7838\\u5230)','砸伤', data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u5207\\u5272)|(\\u4fee\\u5272)|(\\u5272\\u65ad)|(\\u5272\\u5f00)|(\\u5272\\u9664)|(\\u5207\\u9664)|(\\u5272\\u7834)','割伤', data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'\\u7ef7\\u65ad','崩脱', data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u71c3\\u7206)|(\\u7206\\u70b8)|(\\u7206\\u71c3)|(\\u5f15\\u71c3)|(\\u95ea\\u7206)|(\\u95ea\\u71c3)','爆裂', data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u4e0b\\u6ed1)|(\\u6ed1\\u5165)|(\\u6ed1\\u52a8)','滑落', data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u6324\\u538b)','挤伤', data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u7ede\\u5165)','绞伤', data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u649e\\u5230)|(\\u649e\\u51fb)|(\\u78b0\\u649e)|(\\u78b0\\u843d)','撞倒', data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u8e29\\u5230)|(\\u8e29\\u7a7a)|(\\u8e29\\u788e)','踩踏', data['详细描述'].iloc[i])\n",
    "    data['详细描述'].iloc[i]=re.sub(r'(\\u503e\\u659c)','倾倒', data['详细描述'].iloc[i])\n",
    "#     上一个语句已经改为涂装车间，不需要进行归并了\n",
    "#     data['详细描述'].iloc[i]=re.sub(r'(\\u6d82\\u88c5\\u79d1)','涂装车间', data['详细描述'].iloc[i])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 提取部门、特征项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['department']=''\n",
    "data['trait']=''\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_r(s,k): #s为apart或者r  k为1或2\n",
    "    for j in range(len(data)):\n",
    "        for i in range(len(s)):\n",
    "            if s[i] in str(data['详细描述'][j]):\n",
    "                w = data.iloc[:,k][j]\n",
    "                data.iloc[:,k][j] = str(w)+','+s[i]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_r(apart,1)\n",
    "extract_r(r,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去除前面的逗号\n",
    "data['department']=data['department'].apply(lambda x:x.strip(','))\n",
    "data['trait'] =data['trait'].apply(lambda x:x.strip(','))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 验证部门与特征项的的正确与否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['test_1']=False\n",
    "data['test_2']=False\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    for k in range(1,3):\n",
    "        for i in range(len(data)):\n",
    "            if ',' in data.iloc[:,k][i]:\n",
    "                b = data.iloc[:,k][i].split(',')\n",
    "                for j in range(len(b)):\n",
    "                    if b[j] in data['详细描述'][i]:\n",
    "                        data.iloc[:,k+2][i]=True\n",
    "                    elif not b[j] in data['详细描述'][i]:\n",
    "                        data.iloc[:,k+2][i]=False\n",
    "                        break\n",
    "            else:\n",
    "                if data.iloc[:,k][i] in data['详细描述'][i]:\n",
    "                    data.iloc[:,k+2][i]=True\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['test_1'].value_counts()\n",
    "data['test_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 部门与特征项的关联关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 三、导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,3): \n",
    "    for i in range(len(data)):\n",
    "        if len(data.iloc[:,k][i])==0:\n",
    "            data.iloc[:,k][i]=np.nan\n",
    "dat=data.iloc[:,:3]\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nan 的数量\n",
    "count=0\n",
    "for i in range(len(data)):\n",
    "    if dat['trait'][i] is np.nan:\n",
    "        count = count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 特征项的关联"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_trait =dat.dropna(subset=['trait'])\n",
    "dat_trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = dat_trait['trait'].apply(lambda x:x.split(',')).tolist()\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('demo.txt','w',encoding = 'utf-8') as  f:\n",
    "    f.write(str(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16 部门与特征项之间的原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_department = dat.dropna()\n",
    "dat_depart = dat_department[['department','trait']]\n",
    "dat_depart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#候选项集\n",
    "d_t = dat_depart.apply(lambda x:x['department'] + ',' + x['trait'],axis=1).apply(lambda x:x.split(','))\n",
    "lst_apart = d_t.tolist()\n",
    "lst_apart# 原始数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lst_apart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17 绘制雷达图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(depart):\n",
    "    l = []  #车间\n",
    "    ss=[]\n",
    "    for key in lst_apart:\n",
    "        if depart in key:\n",
    "            l.append(key)\n",
    "    for value in r:       #致因项\n",
    "        con = 0     \n",
    "        for key in l:     #车间\n",
    "            if value in key: \n",
    "                s = 1\n",
    "                con = con + s\n",
    "            else:\n",
    "                s = 0\n",
    "        percent = con/len(l)\n",
    "        pd.DataFrame()\n",
    "        ss.append([value,depart,con,percent])\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jidian = pd.DataFrame(dataset('机电车间'),columns=['致因项','部门','次数','百分比']).sort_values(by=['次数'],ascending=False)\n",
    "data_jidian.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jidian_eng=data_jidian.head(8)\n",
    "jidian_english=jidian_eng.replace({'坠落':'come down','滑落':'slide','割伤':'cut','砸伤':'bruise','爆裂':'burst','压载':'ballast','倾倒':'dump','修理':'repair'})\n",
    "jidian_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chuanti =pd.DataFrame(dataset('船体车间'),columns=['致因项','部门','次数','百分比']).sort_values(by=['次数'],ascending=False)\n",
    "data_chuanti.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuanti_eng=data_chuanti.head(8)\n",
    "chuanti_english=chuanti_eng.replace({'坠落':'come down','滑落':'slide','割伤':'cut','砸伤':'bruise','脱落':'fall off','踩踏':'trample','倾倒':'dump','磕碰':'bump'})\n",
    "chuanti_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fuwu =pd.DataFrame(dataset('服务车间'),columns=['致因项','部门','次数','百分比']).sort_values(by=['次数'],ascending=False)\n",
    "data_fuwu.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuwu_eng=data_fuwu.head(8)\n",
    "fuwu_english=fuwu_eng.replace({'坠落':'come down','滑落':'slide','割伤':'cut','起钩':'hook','脱落':'fall off','吊起':'hoist','倾倒':'dump','起吊':'lifting'})\n",
    "fuwu_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qiyun =pd.DataFrame(dataset('起运车间'),columns=['致因项','部门','次数','百分比']).sort_values(by=['次数'],ascending=False)\n",
    "data_qiyun.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qiyun_eng=data_qiyun.head(8)\n",
    "qiyun_english=qiyun_eng.replace({'坠落':'come down','滑落':'slide','起钩':'hook','失稳':'instability','脱落':'fall off','避让':'avoid','倾倒':'dump','吊起':'hoist'})\n",
    "qiyun_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xizhuang = pd.DataFrame(dataset('舾装车间'),columns=['致因项','部门','次数','百分比']).sort_values(by=['次数'],ascending=False)\n",
    "data_xizhuang.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xizhuang_eng=data_xizhuang.head(8)\n",
    "xizhuang_english=xizhuang_eng.replace({'坠落':'come down','滑落':'slide','割伤':'cut','砸伤':'bruise','脱落':'fall off','失稳':'instability','倾倒':'dump','磕碰':'bump'})\n",
    "xizhuang_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chuantai = pd.DataFrame(dataset('船台工区'),columns=['致因项','部门','次数','百分比']).sort_values(by=['次数'],ascending=False)\n",
    "data_chuantai.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuantai_eng=data_chuantai.head(8)\n",
    "chuantai_english=chuantai_eng.replace({'坠落':'come down','滑落':'slide','割伤':'cut','砸伤':'bruise','清理':'repair','吊起':'hoist','倾倒':'dump','起吊':'lifting'})\n",
    "chuantai_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuzhuang = pd.DataFrame(dataset('涂装车间'),columns=['致因项','部门','次数','百分比']).sort_values(by=['次数'],ascending=False)\n",
    "data_tuzhuang.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuzhuang_eng=data_tuzhuang.head(8)\n",
    "tuzhuang_english=tuzhuang_eng.replace({'坠落':'come down','击伤':'wound','割伤':'cut','裂伤':'laceration','脱落':'fall off','失稳':'instability','倾倒':'dump','爆裂':'burst'})\n",
    "tuzhuang_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "\n",
    "fig = plt.figure(figsize=(15,6),dpi=500)\n",
    "ax1 = fig.add_subplot(241,polar=True)\n",
    "ax1.set_title('Hull workshop')\n",
    "angles_1 = np.linspace(0, 2*np.pi,8, endpoint=False)\n",
    "angles_1 = np.concatenate((angles_1,[angles_1[0]])) \n",
    "values = data_chuanti['百分比'].head(8)\n",
    "feature = chuanti_english['致因项'].head(8)\n",
    "values = np.concatenate((values,[values.iloc[0]]))    # 数值,百分比\n",
    "feature = np.concatenate((feature,[feature.iloc[0]])) # 事故致因项\n",
    "ax1.plot(angles_1, values, '*-', linewidth=2, linestyle='--',markersize=10) #线条\n",
    "ax1.fill(angles_1, values, alpha=0.25)  #填充颜色\n",
    "\n",
    "# 标签\n",
    "ax1.set_thetagrids(angles_1 * 180/np.pi, feature, fontproperties = \"SimHei\")\n",
    "ax1.grid(True)\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(242, polar=True)\n",
    "ax2.set_title('Electromechanical workshop')\n",
    "angles_2 = np.linspace(0, 2*np.pi,8, endpoint=False)\n",
    "angles_2 = np.concatenate((angles_2,[angles_2[0]])) \n",
    "values = data_jidian['百分比'].head(8)\n",
    "feature = jidian_english['致因项'].head(8)\n",
    "values = np.concatenate((values,[values.iloc[0]]))    # 数值,百分比\n",
    "feature = np.concatenate((feature,[feature.iloc[0]])) # 事故致因项\n",
    "ax2.plot(angles_2, values, '*-', linewidth=2,linestyle='--',markersize=10)\n",
    "ax2.fill(angles_2, values, alpha=0.25)\n",
    "# 标签\n",
    "ax2.set_thetagrids(angles_2 * 180/np.pi, feature, fontproperties = \"SimHei\")\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3=fig.add_subplot(243, polar=True)\n",
    "ax3.set_title('Shipping workshop')\n",
    "angles_3 = np.linspace(0, 2*np.pi,8, endpoint=False)\n",
    "angles_3 = np.concatenate((angles_3,[angles_3[0]])) \n",
    "values = data_qiyun['百分比'].head(8)\n",
    "feature = qiyun_english['致因项'].head(8)\n",
    "values = np.concatenate((values,[values.iloc[0]]))    # 数值,百分比\n",
    "feature = np.concatenate((feature,[feature.iloc[0]])) # 事故致因项\n",
    "ax3.plot(angles_3, values, '*-', linewidth=2,linestyle='--',markersize=10)\n",
    "ax3.fill(angles_3, values, alpha=0.25)\n",
    "# 标签\n",
    "ax3.set_thetagrids(angles_3 * 180/np.pi, feature, fontproperties = \"SimHei\")\n",
    "ax3.grid(True)\n",
    "\n",
    "ax4=fig.add_subplot(244, polar=True)\n",
    "ax4.set_title('Service workshop')\n",
    "angles_4 = np.linspace(0, 2*np.pi,8, endpoint=False)\n",
    "angles_4 = np.concatenate((angles_4,[angles_4[0]])) \n",
    "values = data_fuwu['百分比'].head(8)\n",
    "feature = fuwu_english['致因项'].head(8)\n",
    "values = np.concatenate((values,[values.iloc[0]]))    # 数值,百分比\n",
    "feature = np.concatenate((feature,[feature.iloc[0]])) # 事故致因项\n",
    "ax4.plot(angles_4, values, '*-', linewidth=2,linestyle='--',markersize=10)\n",
    "ax4.fill(angles_4, values, alpha = 0.25)\n",
    "# 标签\n",
    "ax4.set_thetagrids(angles_4 * 180/np.pi, feature, fontproperties = \"SimHei\")\n",
    "ax4.grid(True)\n",
    "\n",
    "ax5=fig.add_subplot(245, polar=True)\n",
    "ax5.set_title('Painting workshop')\n",
    "angles_5 = np.linspace(0, 2*np.pi,8, endpoint=False)\n",
    "angles_5 = np.concatenate((angles_5,[angles_5[0]])) \n",
    "values = data_tuzhuang['百分比'].head(8)\n",
    "feature = tuzhuang_english['致因项'].head(8)\n",
    "values = np.concatenate((values,[values.iloc[0]]))    # 数值,百分比\n",
    "feature = np.concatenate((feature,[feature.iloc[0]])) # 事故致因项\n",
    "ax5.plot(angles_5, values, '*-', linewidth=2,linestyle='--',markersize=10)\n",
    "ax5.fill(angles_5, values, alpha=0.25)\n",
    "# 标签\n",
    "ax5.set_thetagrids(angles_5 * 180/np.pi, feature, fontproperties = \"SimHei\")\n",
    "ax5.grid(True)\n",
    "\n",
    "ax6=fig.add_subplot(246, polar=True)\n",
    "ax6.set_title('Outfitting workshop')\n",
    "angles_6 = np.linspace(0, 2*np.pi,8, endpoint=False)\n",
    "angles_6 = np.concatenate((angles_6,[angles_6[0]])) \n",
    "values = data_xizhuang['百分比'].head(8)\n",
    "feature = xizhuang_english['致因项'].head(8)\n",
    "values = np.concatenate((values,[values.iloc[0]]))    # 数值,百分比\n",
    "feature = np.concatenate((feature,[feature.iloc[0]])) # 事故致因项\n",
    "ax6.plot(angles_6, values, '*-', linewidth=2,linestyle='--',markersize=10)\n",
    "ax6.fill(angles_6, values, alpha=0.25)\n",
    "# 标签\n",
    "ax6.set_thetagrids(angles_6 * 180/np.pi, feature, fontproperties = \"SimHei\")\n",
    "ax6.grid(True)\n",
    "\n",
    "ax7=fig.add_subplot(247, polar=True)\n",
    "ax7.set_title('Slipway workshop')\n",
    "fig.tight_layout()\n",
    "angles_7 = np.linspace(0, 2*np.pi,8, endpoint=False)\n",
    "angles_7 = np.concatenate((angles_7,[angles_7[0]])) \n",
    "values = data_chuantai['百分比'].head(8)\n",
    "feature = chuantai_english['致因项'].head(8)\n",
    "values = np.concatenate((values,[values.iloc[0]]))    # 数值,百分比\n",
    "feature = np.concatenate((feature,[feature.iloc[0]])) # 事故致因项\n",
    "ax7.plot(angles_7, values, '*-', linewidth=2,linestyle='--',markersize=10)\n",
    "ax7.fill(angles_7, values, alpha=0.25)\n",
    "# 标签\n",
    "ax7.set_thetagrids(angles_7 * 180/np.pi, feature, fontproperties = \"SimHei\")\n",
    "ax7.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、部门与特征之间的联系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createC1(dataSet):\n",
    "    C1 = []\n",
    "    for transaction in dataSet: #数据集中每一条事务\n",
    "        for item in transaction: #事务中的每一个项集\n",
    "            if not {item} in C1: #判断每一个项集在不在候选集合中\n",
    "                C1.append({item})#添加不在候选集中的那些项集\n",
    "                C1.sort() #排序\n",
    "    return list(map(frozenset, C1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scanD(D, Ck, minSupport):\n",
    "    ssCnt = {}          #字典的形式存放项集及其出现次数，{项集:次数}\n",
    "    for tid in D:       #每一条事务集\n",
    "        for can in Ck:  #候选集中每一个项集\n",
    "            if can.issubset(tid): #判断can是否是tid的子集，返回的是布尔型数据\n",
    "                ssCnt[can] = ssCnt.get(can, 0) + 1 \n",
    "    numItems = float(len(D))         #数据集长度\n",
    "    retList= []                      #频繁项集\n",
    "    supportData = {} #候选集项Ck的支持度字典(key:候选项， value:支持度)\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems #计算每一项集的支持度\n",
    "        supportData[key] = support #将所有项集及其支持度以字典的形式放入supportData\n",
    "        if support >= minSupport: #如果支持度满足最小支持度要求（≥最小支持度）\n",
    "            retList.append(key) #把满足支持度的项集放入频繁项集retList     \n",
    "    return retList, supportData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aprioriGen(Lk):\n",
    "    Ck = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            L1 = Lk[i]\n",
    "            L2 = Lk[j]\n",
    "            C = Lk[i] | Lk[j]\n",
    "            if not C in Ck and (len(C)==len(Lk[0])+1):\n",
    "                Ck.append(Lk[i] | Lk[j])\n",
    "    return Ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(D, minSupport):\n",
    "    C1 = createC1(D) #生成候选1项集\n",
    "    L1, supportData = scanD(D, C1, minSupport) #生成频繁1项集和支持度列表\n",
    "    L = [L1] #将频繁1项集放入L中\n",
    "    k=2 #项集数，初始值设为2\n",
    "    while (len(L[-1]) > 0): #如果L中最后项集中的元素数不为0则持续循环\n",
    "        Ck = aprioriGen(L[-1]) #生成候选k项集\n",
    "        Lk, supK = scanD(D, Ck, minSupport) #根据候选k项集，生成频繁k项集和支持度列表\n",
    "        supportData.update(supK) #更新支持度列表\n",
    "        L.append(Lk) #更新频繁项集L\n",
    "        k=k+1\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#二项集\n",
    "def calcConf(freqSet, H, supportData, brl, minConf):\n",
    "    prunedH = [] #放置置信度过滤后的可以出现在规则右部的元素列表\n",
    "    for conseq in H: #对关联规则右部元素列表进行循环\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] #计算规则的置信度\n",
    "        lift = conf/supportData[conseq]\n",
    "        counti = supportData[freqSet]*len(lst_apart) #出现次数\n",
    "        if conf >= minConf: #判断置信度是否满足最小置信度的要求\n",
    "             for i in apart_update:   #去掉致因项之间的关联\n",
    "                if (i in conseq) | (i in freqSet-conseq): # 前者或后者有部门\n",
    "                    print(freqSet-conseq,'-->',conseq,'support_data:',round(supportData[freqSet],3),'conf:',round(conf,3),'lift:',round(lift,3),'count:',round(counti,3)) #打印强关联规则\n",
    "                    brl.append((freqSet-conseq, conseq, supportData[freqSet],conf,lift,counti)) #把强关联规则追加到 brl\n",
    "                    prunedH.append(conseq) #将经过置信度过滤的元素，放入prunedH\n",
    "    return prunedH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多项集\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf):\n",
    "    Hmp = True\n",
    "    while Hmp:\n",
    "        Hmp = False\n",
    "        H = calcConf(freqSet, H, supportData, brl, minConf)\n",
    "        H = aprioriGen(H)\n",
    "        Hmp = not(H == [] or len(H[0]) == len(freqSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRules(L, supportData, minConf):\n",
    "    bigRuleList = [] #强关联规则容器\n",
    "    for i in range(1, len(L)): #对所有频繁项集循环操作，这里需要注意的是频繁1项集不存在关联规则\n",
    "        for freqSet in L[i]: # 对频繁项集中的每个子集关联规则进行挖掘\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList,minConf) #频繁多项集\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf) #频繁二项集\n",
    "    return bigRuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#支持度、频繁项集\n",
    "L,suppData=apriori(lst_apart,minSupport=0.01)\n",
    "suppData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#置信度\n",
    "cc = generateRules(L,suppData,minConf=0.1)\n",
    "len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转变冷冻集合\n",
    "def filter_data(s):\n",
    "    import re\n",
    "    match = re.search(r\"('(.*)')\" , s).group()\n",
    "    if match:\n",
    "        s = eval(match)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_items=pd.DataFrame(cc,columns=['Source','Target','support_data','conf','lift','count'])\n",
    "related_items['Source']=related_items['Source'].astype(str)\n",
    "related_items['Target']=related_items['Target'].astype(str)\n",
    "related_items['Target'] = related_items['Target'].apply(filter_data)\n",
    "related_items['Source'] = related_items['Source'].apply(filter_data)\n",
    "related_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_items.to_csv(r'E:\\基于文本挖掘的船舶建造事故致因分析\\Relate.csv',encoding='utf_8_sig')\n",
    "#部门与事故致因项置信度写进excel中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apart_trait=pd.DataFrame(r).rename(columns={0:'trait'})\n",
    "for i in range(len(apart_update)):\n",
    "    apart_trait.loc[30+i] = apart_update[i]\n",
    "apart_trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apart_trait.to_csv(r'E:\\基于文本挖掘的船舶建造事故致因分析\\apart_trait.csv',encoding=\"utf_8_sig\")\n",
    "# 所有部门与特征项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卡方检验：部门与致因项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 双向无序R*C卡方检验：得到的p值是整体P值，若p<0.05,则这几组中有一组与其他组不同，但是具体哪一组并不知道，需要进行两两检验。\n",
    "# 两两检验的其中一种：bonferroni校正法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd = pd.read_csv(r'E:\\基于文本挖掘的船舶建造事故致因分析\\Relate_SPSS.csv',encoding=\"utf_8_sig\")\n",
    "# dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd['count'] = ''\n",
    "# for j in range(len(dd)):\n",
    "#     con = 0\n",
    "#     for value in lst_apart:\n",
    "#         if len(dd['Source'].iloc[j])!=12:\n",
    "#             if (dd['Source'].iloc[j] in value) & (dd['Target'].iloc[j] in value):\n",
    "#                 con = con + 1\n",
    "#         else:\n",
    "#             ddc = re.findall(r\"([\\u4e00-\\u9fa5]{2})\",dd['Source'].iloc[j])\n",
    "#             if (ddc[0] in value) & (dd['Target'].iloc[j] in value) & (ddc[1] in value):\n",
    "#                 con = con + 1\n",
    "#     dd['count'].iloc[j] = con\n",
    "# dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_csv(r'E:\\基于文本挖掘的船舶建造事故致因分析\\Related_spss.csv',encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以在related_items中直接删除重复的值，得到的就是频数可以直接用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算致因项在部门的百分比 : 用雷达图计算百分比，根据关联规则算的总数不对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd['Source'] = dd['Source'].apply(lambda x:x.split(','))\n",
    "# dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd2 = dd.explode('Source').reset_index().drop(columns=['index'])\n",
    "# dd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(dd2)):\n",
    "#     if \"'\" in dd2['Source'].iloc[i]:\n",
    "#         dd2['Source'].iloc[i]= re.search(r\"([\\u4e00-\\u9fa5]{2})\",dd2['Source'].iloc[i]).group()\n",
    "# dd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd3 = dd2[['Source','Target','count']]\n",
    "# per = dd3.groupby(['Target','Source']).agg({'count':'sum'})\n",
    "# per.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这样算是多加了的\n",
    "# su = per.reset_index().groupby('Target')['count'].sum().to_frame()\n",
    "# su\n",
    "#对原始数据dd求部门和\n",
    "# su = dd.groupby(['Target'])['count'].sum().to_frame()\n",
    "# su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pert = pd.merge(per.reset_index(),su,on = 'Target')\n",
    "# pert['percent']  = pert['count_x']/pert['count_y']\n",
    "# pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pert.to_csv(r'E:\\基于文本挖掘的船舶建造事故致因分析\\percent.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 散点图：支持度+提升度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#事故发生部门与事故致因项之间\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "fig = plt.figure(figsize=(10,6),dpi=500)\n",
    "x = related_items['support_data'].values\n",
    "y = related_items['lift'].values\n",
    "\n",
    "cm = plt.cm.get_cmap('RdYlBu')\n",
    "\n",
    "z = related_items['conf'].values\n",
    "\n",
    "sc = plt.scatter(x,y,c=z,cmap=cm)\n",
    "plt.colorbar(sc,label='Confidence')\n",
    "\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Lift')\n",
    "\n",
    "# plt.title('事故部门与致因项')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 二、事故致因之间的联系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createC1(dataSet):\n",
    "    C1 = [[i] for i in np.unique(np.concatenate(lst).ravel())]\n",
    "    return C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = createC1(lst)\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判断是否满足子集的条件,\n",
    "#找出所有子集\n",
    "def inn(ls,items):\n",
    "    N = len(items)\n",
    "    flag = 0\n",
    "    for i in range(2 ** N):\n",
    "        combo = []\n",
    "        for j in range(N):\n",
    "            if (i >> j) % 2 :\n",
    "                combo.append(items[j])\n",
    "        if ls == combo:\n",
    "            flag += 1\n",
    "        else:\n",
    "            flag += 0\n",
    "    if flag > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s所有子集列表\n",
    "s=[]\n",
    "for q in lst:\n",
    "    N = len(q)\n",
    "    for i in range(2**N):\n",
    "        combo = []\n",
    "        for j in range(N):\n",
    "            if (i>>j)%2:\n",
    "                combo.append(q[j])\n",
    "                s.append(combo)\n",
    "#列表去重之后，原始数据集中的所有子集\n",
    "com=[]\n",
    "for i in s:\n",
    "    if i not in com:\n",
    "        com.append(i)\n",
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#列表去重之后，原始数据集中的所有子集\n",
    "com=[]\n",
    "for i in s:\n",
    "    if i not in com:\n",
    "        com.append(i)\n",
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算子集出现的频数\n",
    "def scan(lst,com): \n",
    "    dic={}\n",
    "    for i in com:\n",
    "        for j in lst:\n",
    "            if inn(i,j):\n",
    "                dic[str(i)] = dic.get(str(i),0) + 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "for i in com:\n",
    "    for j in lst:\n",
    "        if inn(i,j):\n",
    "            dic[str(i)] = dic.get(str(i),0) + 1\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#产生庞大的数据集，把没有出现过的数据集删除\n",
    "def get_support(lst,min_support):\n",
    "    dic = {}\n",
    "    dic.update(scan(lst,com))\n",
    "    num = len(lst)    \n",
    "    support_dic = {}\n",
    "    count = 0\n",
    "    for key,value in dic.items():\n",
    "        support = value/num\n",
    "        if support >= min_support:\n",
    "            support_dic[key] =support\n",
    "            count += 1 \n",
    "    return support_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_su=get_support(lst,0.005)\n",
    "reason_su# 频繁项集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rlue(support_dic):\n",
    "    count = 0\n",
    "    rulelist = []\n",
    "    for key,value in support_dic.items():#支持度频繁项集\n",
    "        n = len(eval(key))\n",
    "        if  n == 2 :\n",
    "            front = eval(key)[0]\n",
    "            after = eval(key)[1]\n",
    "            confi = support_dic[key]/support_dic[str([front])]\n",
    "            lifti = confi/support_dic[str([after])]\n",
    "            counti = support_dic[key]*len(lst)  #次数\n",
    "            print(f'{[front]}','-->',f'{[after]}','\\n',#打印所有前键和后键\n",
    "                     'together support:',round(support_dic[key],3),',',#联合支持度也就是联合概率\n",
    "                     'conf:',round(confi,3),',',\n",
    "                     'lift:',round(lifti,3),','\n",
    "                     'count:',round(counti,3))\n",
    "            rulelist.append((front,after,round(support_dic[key],3),round(confi,3),round(lifti,3),round(counti,3)))\n",
    "        elif n > 2:\n",
    "            front = eval(key)[:n-1]\n",
    "            after = eval(key)[-1]\n",
    "            confi = support_dic[key]/support_dic[str(front)]\n",
    "            lifti = confi/support_dic[str([after])]\n",
    "            counti =  support_dic[key]*len(lst)\n",
    "            print(f'{[front]}','-->',f'{[after]}','\\n',\n",
    "             'support:',round(support_dic[key],3),',',#联合支持度也就是联合概率\n",
    "             'conf:',round(confi,3),',',\n",
    "             'lift:',round(lifti,3),','\n",
    "             'count:',round(counti,3))\n",
    "            rulelist.append((front,after,round(support_dic[key],3),round(confi,3),round(lifti,3),round(counti,3)))\n",
    "        count += 1\n",
    "    return rulelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reason=get_rlue(get_support(lst,0.005))\n",
    "reason   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc_11=pd.DataFrame(reason,columns=['Source','Target','support','conf','lift','count'])\n",
    "cc_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_11.to_csv(r'E:\\基于文本挖掘的船舶建造事故致因分析\\trai_Related.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trait_xls=pd.DataFrame(base)\n",
    "trait_xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_xls.to_csv(r'E:\\基于文本挖掘的船舶建造事故致因分析\\trai.csv',encoding='UTF_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事故致因项之间\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "fig = plt.figure(figsize=(10,6),dpi=500)\n",
    "x = cc_11['support'].values\n",
    "y = cc_11['lift'].values\n",
    "\n",
    "cm = plt.cm.get_cmap('RdYlBu')\n",
    "\n",
    "z = cc_11['conf'].values\n",
    "\n",
    "sc = plt.scatter(x,y,c=z,cmap=cm)\n",
    "plt.colorbar(sc,label='Confidence')\n",
    "\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Lift')\n",
    "\n",
    "# plt.title('事故部门与致因项')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卡方检验：事故致因项（有序）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 双向有序的R*C列表: 要用非参数检验 + 两两检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有序的先计算频数,事故致因项是有序的，从原始数据中找出所有子集以及所有子集的频数，\n",
    "# 事故发生部门与事故致因项之间的频数是正确的，支持度*原始数据总长度=频数\n",
    "# 存在的多个致因项与车间部门之间的关联关系频数也可以这样算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_count = cc_11[['Source','Target','count']]\n",
    "cc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_count.to_csv(r'E:\\基于文本挖掘的船舶建造事故致因分析\\trait_Spss.csv',encoding='UTF_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
